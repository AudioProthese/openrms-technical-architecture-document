---
title: "Document d'Architecture Technique"
subtitle: "AudioProthese+"
author:
  - Matteo ZINUTTI
  - Fabien CHEVALIER
  - Hakim AFARMACH
date: "2025-05-15"
titlepage: true
titlepage-logo: "icon.jpeg"
logo: "icon.jpeg"
logo-width: "35mm"
toc: true
toc-own-page: true
keywords: [AudioProthese+, Technical Architecture, Documentation]
lang: fr
titlepage-background: "background/background.pdf"
titlepage-rule-color: "000000"
---

# Introduction

## Objectif du document

Ce document d‚Äôarchitecture technique a pour objectif de pr√©senter, de mani√®re d√©taill√©e et structur√©e, l‚Äôarchitecture de la plateforme AudioProthese+. Il s‚Äôadresse principalement aux architectes, d√©veloppeurs, administrateurs syst√®me et toute personne impliqu√©e dans la conception, le d√©ploiement et l‚Äôexploitation du syst√®me d‚Äôinformation.

## Contexte

AudioProth√®se+ est un r√©seau de centres d'audioproth√®se implant√© dans plusieurs villes en France, offrant des services de diagnostic, d'appareillage et de suivi pour les personnes souffrant de troubles auditifs.

Avec une pr√©sence dans plus de 50 villes et un si√®ge social √† Paris, l'entreprise g√®re des donn√©es sensibles de patients et utilise des √©quipements m√©dicaux de pointe connect√©s.

Face √† l'augmentation des cybermenaces dans le secteur de la sant√© et √† la n√©cessit√© de se conformer aux r√©glementations strictes en mati√®re de protection des donn√©es m√©dicales, AudioProth√®se+ a d√©cid√© de renforcer significativement sa s√©curit√© informatique.

Pour se faire, l'entreprise souhaite mettre en place et d√©ployer des solutions d‚Äôautomatisation, de r√©silience et d‚Äôobservabilit√© afin d‚Äôam√©liorer la fiabilit√© de son infrastructure. Ce projet ambitieux vise √† concevoir et d√©ployer l'infrastructure n√©cessaire de mani√®re automatis√©e, en utilisant des pratiques DevOps et des solutions open source. L'objectif est de cr√©er une infrastructure flexible, √©volutive et √©conomiquement efficace, tout en garantissant un niveau de s√©curit√© optimal pour prot√©ger les donn√©es des patients et l'int√©grit√© des syst√®mes d'AudioProth√®se+.

## Port√©e du document

Ce document couvre l‚Äôensemble des aspects techniques de la plateforme, notamment‚ÄØ:

- L‚Äôarchitecture globale du syst√®me
- Les choix technologiques (Kubernetes, microservices, CI/CD, etc.)
- Les composants principaux et leurs interactions
- Les principes de s√©curit√© et de haute disponibilit√©
- Les strat√©gies de d√©ploiement et de supervision

Il ne s'agira pas ici de d√©tailler les aspects fonctionnels de la plateforme, qui sont eux d√©taill√©s dans un [wiki d√©di√©](https://audioprothese.github.io/openmrs-architecture-documentation/). Ce document se concentre sur l'architecture technique et les choix technologiques qui sous-tendent la mise en ≈ìuvre de la plateforme AudioProth√®se+.

## Public vis√©

Ce document s‚Äôadresse aux‚ÄØ:

- Architectes techniques
- D√©veloppeurs
- Ing√©nieurs DevOps
- Administrateurs syst√®me
- Responsables de la s√©curit√© informatique

## R√©partition des r√¥les et responsabilit√©s

**Matteo ZINUTTI**  
*R√¥le : Ing√©nieur DevOps*  
Responsabilit√©s :  

- Mise en ≈ìuvre des stacks d'observabilit√© Open-Source (Grafana, Prometheus, Loki)  
- Synchronisation des secrets Azure

---

**Fabien CHEVALIER**  
*R√¥le : Ing√©nieur DevOps*  
Responsabilit√©s :  

- Mise en place de l'industrialisation de la plateforme (Terraform, Helm, ArgoCD)  
- Gestion des d√©ploiements CI/CD  
- Mise en place de la documentation as code

---

**Hakim AFARMACH**  
*R√¥le : Ing√©nieur DevOps*  
Responsabilit√©s :  

- Mise en place des solutions de s√©curit√© (Oath2, Zero-trust)  
- Mise en place des configurations Kubernetes

---

### M√©thodologie de travail

Mise en place de feature branches pour chaque fonctionnalit√© ou correctif, avec des pull requests pour la revue de code. Organisation de sprints de d√©veloppement de deux semaines, avec des r√©unions quotidiennes pour le suivi de l'avancement et la r√©solution des blocages. Utilisation d'outils de gestion de projet inclus √† GitHub pour le suivi des t√¢ches et des bugs.

Le plateforme √† √©t√© d√©velopp√©e en collaboration constante, avec une sp√©cialit√© pour chaque membre de l'√©quipe. Les r√¥les ont √©t√© r√©partis en fonction des comp√©tences et des int√©r√™ts de chacun, et sont d√©taill√©s ci-dessus.

Un soin important √† √©t√© apport√© √† la documentation, tant au niveau du code source (commentaires, README) qu'au niveau de la documentation technique (ce document). La documentation est consid√©r√©e comme un √©l√©ment essentiel pour assurer la maintenabilit√© et la compr√©hension de l'architecture par les futurs intervenants. Il a d'ailleurs √©t√© d√©cid√© de mettre en place une documentation as code, permettant de versionner la documentation avec le code source et de la maintenir √† jour de mani√®re coh√©rente. Cette documentation est h√©berg√©e sur GitHub et accessible aux membres de l'√©quipe ainsi qu'aux parties prenantes du projet.

## Pr√©sentation des outils et solutions techniques

Dans le cadre de l‚Äôindustrialisation et de la supervision de la plateforme AudioProth√®se+, plusieurs outils et services ont √©t√© s√©lectionn√©s afin de garantir la s√©curit√©, la fiabilit√© et la scalabilit√© de l‚Äôinfrastructure. Le choix de ces solutions s‚Äôinscrit dans une d√©marche DevOps et repose sur des technologies open source et des services cloud √©prouv√©s.

Cette section pr√©sente les outils et solutions retenus, ainsi que leurs r√¥les respectifs dans l‚Äôarchitecture technique de la plateforme. Le d√©tail des configurations et leur justification seront abord√©s dans les sections suivantes.

### Azure Cloud

Azure est la plateforme cloud choisie pour h√©berger l‚Äôensemble de l‚Äôinfrastructure d‚ÄôAudioProth√®se+. Azure offre une large gamme de services cloud, notamment des machines virtuelles, des bases de donn√©es, des services de stockage et des outils de gestion et de s√©curit√©. L‚Äôutilisation d‚ÄôAzure permet √† AudioProth√®se+ de b√©n√©ficier d‚Äôune infrastructure scalable, r√©siliente et s√©curis√©e, tout en r√©duisant les co√ªts d‚Äôexploitation.

### Kubernetes via AKS

Kubernetes est utilis√© comme orchestrateur de conteneurs pour le d√©ploiement et la gestion de l‚Äôapplication OpenMRS. Il permet d‚Äôautomatiser la mise √† l‚Äô√©chelle, la r√©silience et la maintenance des services applicatifs, tout en offrant une grande flexibilit√© dans la gestion des ressources. Nous utilisons AKS (Azure Kubernetes Service) pour b√©n√©ficier d‚Äôune solution manag√©e, simplifiant ainsi la gestion de l‚Äôinfrastructure sous-jacente.

Le cluster Kubernetes h√©bergera :

- Les microservices de l‚Äôapplication OpenMRS (frontend/backend et gateway)
- Les bases de donn√©es (MariaDB)
- Les services de supervision et de s√©curit√© (Prometheus, Grafana, Loki)
- Les outils de d√©ploiement continu (ArgoCD)

### GitHub et GitHub Actions

GitHub est utilis√© comme plateforme de gestion de code source et de collaboration pour l‚Äô√©quipe de d√©veloppement. Les d√©p√¥ts GitHub contiennent le code source des microservices, ainsi que les fichiers de configuration n√©cessaires au d√©ploiement sur Kubernetes.

GitHub Actions est utilis√© pour automatiser les processus de CI/CD (Int√©gration Continue / D√©ploiement Continu). Il permet de construire, tester et d√©ployer automatiquement les applications √† chaque modification du code source. Les workflows GitHub Actions sont configur√©s pour interagir avec le cluster Kubernetes et d√©ployer les nouvelles versions des microservices.

### Industrialisation et outils DevOps

L‚Äôindustrialisation de la plateforme repose sur plusieurs outils et pratiques DevOps, notamment :

- **Terraform** : utilis√© pour la gestion de l‚Äôinfrastructure en tant que code (IaC). Terraform permet de d√©finir et de provisionner l‚Äôinfrastructure Azure de mani√®re automatis√©e et reproductible.
- **Helm** : utilis√© pour la gestion des packages Kubernetes. Helm permet de simplifier le d√©ploiement et la gestion des applications sur Kubernetes en utilisant des charts, qui sont des ensembles de fichiers de configuration.
- **ArgoCD** : utilis√© pour la gestion des d√©ploiements Kubernetes. ArgoCD permet de synchroniser l‚Äô√©tat de l‚Äôapplication avec le code source, garantissant ainsi que les d√©ploiements sont toujours √† jour et conformes aux sp√©cifications.
- **Prometheus** : utilis√© pour la collecte et la surveillance des m√©triques des applications et de l‚Äôinfrastructure. Prometheus permet de suivre les performances et la sant√© des services d√©ploy√©s sur Kubernetes.
- **Grafana** : utilis√© pour la visualisation des m√©triques collect√©es par Prometheus. Grafana permet de cr√©er des tableaux de bord personnalis√©s pour surveiller l‚Äô√©tat de l‚Äôinfrastructure et des applications.
- **Loki** : utilis√© pour la collecte et l‚Äôanalyse des logs des applications et de l‚Äôinfrastructure. Loki permet de centraliser les logs et de faciliter leur recherche et leur analyse.
- **SonarQube** : utilis√© pour l‚Äôanalyse statique du code source. SonarQube permet de d√©tecter les probl√®mes de qualit√© du code, les vuln√©rabilit√©s et les probl√®mes de s√©curit√©.

# Architecture technique

Cette section pr√©sente sous forme sch√©matique l‚Äôarchitecture technique de la plateforme AudioProth√®se+. Elle illustre les diff√©rents composants de l‚Äôinfrastructure, leurs interactions et les flux de donn√©es entre eux.

## Diagramme d'architecture globale (Azure/Kubernetes)

![Diagramme d'architecture globale AKS](./imgs/k8s-scheme.png)

### R√©partition des namespaces

![Namespaces Kubernetes](./imgs/k8s-namespace.png)

La r√©partition des namespaces Kubernetes est organis√©e de mani√®re √† isoler les diff√©rents environnements et services de la plateforme. Chaque namespace correspond √† un environnement sp√©cifique (d√©veloppement, test, production) ou √† un service particulier (frontend, backend, gateway). Dans notre cas, nous avons organis√© les namespaces par service, l'environnement de production √©tant h√©berg√© sur un cluster AKS d√©di√©. Les namespaces sont les suivants :

- **monitoring** : pour les services de supervision (Prometheus, Grafana)
- **loki** : pour le service de collecte et d'analyse des logs (Loki)
- **alloy** : pour le service Alloy, permettant de scrapper les m√©triques OpenMRS
- **openmrs** : pour les services OpenMRS (frontend, backend, gateway)
- **external-secret-operator** : pour le service de synchronisation des secrets Azure
- **argocd** : pour le service de gestion des d√©ploiements (ArgoCD)
- **app-rooting-system** : pour le service de routage des applications (gateway)
- **cert-manager** : pour la gestion des certificats SSL/TLS

Cette r√©partition est identique sur tous les environnements (dev, prod).

### Architecture des microservices

L'application OpenRMS consiste en plusieurs microservices :

- **OpenMRS Frontend** : l'interface utilisateur de l'application
- **OpenMRS Backend** : le service backend qui g√®re la logique m√©tier et les interactions avec la base de donn√©es.
- **OpenMRS Gateway** : le service de routage qui permet de diriger les requ√™tes vers les diff√©rents microservices en fonction des routes d√©finies.
- **MariaDB** : la base de donn√©es relationnelle utilis√©e par OpenMRS pour stocker les donn√©es des patients et des services.

La communication entre les microservices se fait via des API REST, et chaque service est d√©ploy√© dans son propre pod Kubernetes. Les services sont configur√©s pour √™tre accessibles via des Ingress, permettant de g√©rer les routes et les certificats SSL/TLS.

#### App Routing System

C√¥t√© AKS, le load-balancer frontal est configur√© pour diriger le trafic vers l'`app-routing-system`, qui est le point d'entr√©e principal de l'application. `App Routing System` est un service offert par Azure permettant de synchroniser Azure DNS avec les Ingress Kubernetes. Il s'agit d'un proxy `NGINX` manag√© par Azure.

#### Oath2 Proxy et Zero Trust

![Oath2 Proxy](./imgs/oath2-zero-trust.png)

Prometheus, Alloy et Grafana sont situ√©s derri√®re un proxy Oath2, qui permet de s√©curiser l'acc√®s √† ces services en exigeant une authentification via Oath2. La source de v√©rit√© pour les utilisateurs est l'annuaire Entra ID, permettant donc aux diff√©rents acteurs de se connecter via leurs identifiants Azure pour acc√©der aux services de supervision et de monitoring.

#### External Secret Operator

External Secret Operator est utilis√© pour synchroniser les secrets Azure avec Kubernetes. Il permet de g√©rer les secrets de mani√®re s√©curis√©e et centralis√©e, en les stockant dans Azure Key Vault et en les synchronisant automatiquement avec les secrets Kubernetes. Cela permet de garantir que les secrets sont toujours √† jour et accessibles aux services qui en ont besoin.

![External Secret Operator](./imgs/external-secret-operator.png)

#### Stack d'observabilit√©

La stack d'observabilit√© est compos√©e de plusieurs outils open source permettant de collecter, stocker et visualiser les m√©triques et les logs des applications et de l'infrastructure. Elle comprend :

- **Prometheus** : pour la collecte des m√©triques des applications et de l'infrastructure.
- **Grafana** : pour la visualisation des m√©triques collect√©es par Prometheus.
- **Loki** : pour la collecte et l'analyse des logs des applications et de l'infrastructure.
- **Alloy** : pour le scrapping des m√©triques OpenMRS et leur exposition √† Prometheus.

**Ins√©rer capture d'√©cran des dashboards Grafana ici.**

## Configuration Azure Cloud

La s√©curit√© √©tant un enjeu majeur pour AudioProth√®se+, l'architecture Azure est configur√©e pour garantir un niveau de s√©curit√© √©lev√©. Voici les principales configurations mises en place.

### OIDC pour les pipelines GitHub Actions

![OIDC GitHub Actions](./imgs/oidc-azure.png)

Pour s√©curiser les pipelines GitHub Actions, l'authentification OIDC (OpenID Connect) avec Azure Active Directory est d√©ploy√©e. Cela permet aux workflows GitHub Actions de s'authentifier aupr√®s d'Azure sans avoir √† g√©rer des secrets ou des cl√©s d'acc√®s.

Ce syst√®me d'authentification permet de garantir que seuls les workflows autoris√©s peuvent acc√©der aux ressources Azure, renfor√ßant ainsi la s√©curit√© des d√©ploiements.

### S√©curisation des d√©p√¥ts GitHub infrastructure

Des r√®gles de s√©curit√© sont appliqu√©es aux d√©p√¥ts GitHub contenant les fichiers de configuration Terraform et Helm. Ces r√®gles incluent :

- L'utilisation de branches prot√©g√©es pour les modifications de code
- L'exigence de revues de code avant la fusion des pull requests
- L'activation de l'analyse statique du code avec Trivia au sein des workflows GitHub Actions

### Gestion de l'√©tat des ressources Azure

Le `tfstate` (√©tat des ressources Terraform) est stock√© dans un `Azure Storage Account` s√©curis√©. Cela permet de garantir la coh√©rence de l'√©tat des ressources et d'√©viter les conflits lors des d√©ploiements. Sa mise en place est script√©e au sein d'un fichier `init.sh`, permettant la reproduction de l'environnement de mani√®re automatis√©e.

## Tests et validation

Afin de d√©livrer une plateforme fiable et s√©curis√©e, des tests automatis√©s sont mis en place pour valider les diff√©rentes configurations et d√©ploiements. Ces tests incluent :

- **Scan de vuln√©rabilit√©s** : utilisation de `trivy` pour analyser les images Docker et d√©tecter les vuln√©rabilit√©s connues.
- **Observabilit√©** : v√©rification de la collecte des m√©triques et des logs, ainsi que de la configuration des dashboards Grafana.
- **Tests de performance** : utilisation d'outils de test de charge pour simuler des requ√™tes et mesurer les performances des services d√©ploy√©s.

### Scan de vuln√©rabilit√©s

Les scans de vuln√©rabilit√©s sont int√©gr√©s dans les workflows GitHub Actions, permettant de d√©tecter les vuln√©rabilit√©s dans les images Docker utilis√©es par les microservices. Les r√©sultats des scans sont affich√©s dans les rapports de build, et des alertes sont g√©n√©r√©es en cas de vuln√©rabilit√©s critiques.

### Observabilit√©

Les dashboards Grafana sont configur√©s pour afficher les m√©triques collect√©es par Prometheus et les logs collect√©s par Loki. Des alertes sont d√©finies pour d√©tecter les anomalies de performance ou les erreurs dans les logs, permettant une r√©action rapide en cas de probl√®me. De la m√™me mani√®re, une fois l'architecture d√©ploy√©e, des tests de charge sont effectu√©s pour valider la capacit√© de la plateforme √† g√©rer un volume √©lev√© de requ√™tes.

### Validation

Les modifications d'infrastructure doivent faire l'objet d'une revue de code, prenant la forme d'une `pull request` sur le d√©p√¥t GitHub. Cette `pull request` d√©clenche un `plan` Terraform, permettant de visualiser les modifications apport√©es √† l'infrastructure avant leur application. Une fois valid√©e, la `pull request` est fusionn√©e et le `apply` Terraform est ex√©cut√© pour appliquer les modifications.

# Mise en oeuvre et d√©ploiement

Cette section d√©crit les √©tapes de mise en ≈ìuvre et de d√©ploiement de la plateforme AudioProth√®se+. Elle d√©taille les processus d'industrialisation, de configuration et de d√©ploiement des diff√©rents composants de l'architecture technique.

## Mise en place initiale

La mise en place initiale de la plateforme AudioProth√®se+ n√©cessite plusieurs √©tapes cl√©s, allant de la configuration de l'infrastructure Azure √† la mise en place des services Kubernetes.

Les pr√©requis pour la mise en place initiale incluent :

- Un compte Azure avec les permissions n√©cessaires pour cr√©er des ressources
- Une organisation GitHub permettant d'organiser les d√©p√¥ts et les workflows
- `az cli`, `terraform`, `helm` et `kubectl` install√©s sur la machine de d√©ploiement

### Initialisation du backend Terraform

Pour chaque environnement (dev, prod), il est n√©cessaire de cr√©er un storage account d√©di√© pour stocker l'√©tat Terraform. Le script `init.sh` permet de cr√©er automatiquement les ressources n√©cessaires dans Azure, y compris le groupe de ressources, le compte de stockage et le conteneur pour l'√©tat Terraform.

```bash
#!/bin/bash
set -e

create_terraform_backend() {
    local env=$1
    local location=$2
    local rg_name="rg-openmrscore-${env}"
    local sa_name="openmrscore${env}sav1"
    local container_name="tfstate-${env}"

    echo "====== Configuration Backend Terraform pour l'environnement $env ======"

    echo "Cr√©ation du Resource Group $rg_name..."
    az group create --name "$rg_name" --location "$location" --tags "Environment=$env" "Purpose=TerraformState"
    echo "Resource Group $rg_name cr√©√©."

    echo "Cr√©ation du Storage Account $sa_name..."
    az storage account create \
        --name "$sa_name" \
        --resource-group "$rg_name" \
        --location "$location" \
        --sku "Standard_LRS" \
        --kind "StorageV2" \
        --https-only true \
        --min-tls-version "TLS1_2" \
        --tags "Environment=$env" "Purpose=TerraformState"
    echo "Storage Account $sa_name cr√©√©."

    echo "Cr√©ation du Container $container_name..."
    az storage container create \
        --name "$container_name" \
        --account-name "$sa_name" \
        --auth-mode login
    echo "Container $container_name cr√©√©."
}

if ! az account show > /dev/null 2>&1; then
  echo "Vous n'√™tes pas connect√© √† Azure CLI. Connexion..."
  az login
else
  echo "D√©j√† connect√© √† Azure CLI."
fi

LOCATION="francecentral"

echo -e "\nüèóÔ∏è  CR√âATION DES BACKENDS TERRAFORM"
DEV_BACKEND=$(create_terraform_backend "dev" "$LOCATION")
PROD_BACKEND=$(create_terraform_backend "prod" "$LOCATION")
```

### R√©f√©rencer les backends Terraform

Une fois le backend Terraform cr√©√©, il est n√©cessaire de r√©f√©rencer ce backend dans les fichiers de configuration Terraform. Cela permet √† Terraform de stocker l'√©tat des ressources dans le storage account Azure cr√©√© pr√©c√©demment.

```hcl
# Pour l'environnement de d√©veloppement
terraform {
  backend "azurerm" {
    resource_group_name  = "rg-openmrscore-dev"
    storage_account_name = "openmrscoredevsav1"
    container_name       = "tfstate-dev"
    key                  = "dev.tfstate"
  }
}

# Pour l'environnement de production
terraform {
  backend "azurerm" {
    resource_group_name  = "rg-openmrscore-prod"
    storage_account_name = "openmrscoreprodsav1"
    container_name       = "tfstate-prod"
    key                  = "prod.tfstate"
  }
}
```

### Mettre en place l'OIDC pour les pipelines GitHub Actions

L'authentification OIDC (OpenID Connect) permet √† GitHub Actions d'acc√©der √† Azure sans stocker de secrets dans le d√©p√¥t. Pour notre architecture, nous configurons deux connexions OIDC distinctes: - Une pour le d√©p√¥t d'infrastructure (terraform, IaC) - Une pour le d√©p√¥t d'application (code applicatif).

```bash
#!/bin/bash
set -e  

configure_oidc() {
    local app_name=$1
    local github_org=$2
    local github_repo=$3
    local github_env=$4
    local federated_name=$5

    echo "====== Configuration OIDC pour $app_name ======"
    echo "Cr√©ation de l'application Azure AD..."
    local app_id=$(az ad app create --display-name "$app_name" --query appId -o tsv)
    echo " Application cr√©√©e: $app_id"

    echo "Cr√©ation du Service Principal..."
    local sp_object_id=$(az ad sp create --id "$app_id" --query id -o tsv)
    echo " Service Principal cr√©√© avec Object ID: $sp_object_id"

    local subject="repo:${github_org}/${github_repo}:environment:${github_env}"
    echo "Configuration des identifiants f√©d√©r√©s pour GitHub Actions..."
    az ad app federated-credential create --id "$app_id" \
      --parameters '{
        "name": "'"$federated_name"'",
        "issuer": "https://token.actions.githubusercontent.com",
        "subject": "'"$subject"'",
        "description": "GitHub OIDC pour '"$github_env"'",
        "audiences": ["api://AzureADTokenExchange"]
      }'
    echo "Identifiants f√©d√©r√©s ajout√©s pour: $subject"

    echo "Attribution des autorisations..."
    az role assignment create \
      --assignee "$app_id" \
      --role "Owner" \
      --scope "/subscriptions/$SUBSCRIPTION_ID"
    echo "R√¥le 'Owner' attribu√© √† l'application sur l'abonnement $SUBSCRIPTION_ID"

    echo "$app_id"
}

if ! az account show > /dev/null 2>&1; then
  echo "Vous n'√™tes pas connect√© √† Azure CLI. Connexion..."
  az login
else
  echo "D√©j√† connect√© √† Azure CLI."
fi

TIMESTAMP=$(date +%Y%m%d%H%M%S)
GITHUB_ORG="AudioProthese"
GITHUB_ENV="dev"
SUBSCRIPTION_ID="c2b90606-cc96-463f-aa06-70f32719fe4f"

INFRA_APP_NAME="Github-OIDC-Infra-${TIMESTAMP}"
INFRA_GITHUB_REPO="openmrs-core-infrastructure"
INFRA_FEDERATED_NAME="Infra"

APP_APP_NAME="Github-OIDC-App-${TIMESTAMP}"
APP_GITHUB_REPO="openmrs-distro-referenceapplication"
APP_FEDERATED_NAME="Application"

echo -e "\nCONFIGURATION POUR L'INFRASTRUCTURE"
INFRA_APP_ID=$(configure_oidc "$INFRA_APP_NAME" "$GITHUB_ORG" "$INFRA_GITHUB_REPO" "$GITHUB_ENV" "$INFRA_FEDERATED_NAME")

echo -e "\nCONFIGURATION POUR L'APPLICATION"
APP_APP_ID=$(configure_oidc "$APP_APP_NAME" "$GITHUB_ORG" "$APP_GITHUB_REPO" "$GITHUB_ENV" "$APP_FEDERATED_NAME")

echo -e "\nR√âCAPITULATIF DES CONFIGURATIONS"
echo -e "\n=== POUR L'INFRASTRUCTURE ($INFRA_GITHUB_REPO) ==="
echo "  - AZURE_CLIENT_ID: $INFRA_APP_ID"
echo "  - AZURE_TENANT_ID: $(az account show --query tenantId -o tsv)"
echo "  - AZURE_SUBSCRIPTION_ID: $SUBSCRIPTION_ID"

echo -e "\n=== POUR L'APPLICATION ($APP_GITHUB_REPO) ==="
echo "  - AZURE_CLIENT_ID: $APP_APP_ID"
echo "  - AZURE_TENANT_ID: $(az account show --query tenantId -o tsv)"
echo "  - AZURE_SUBSCRIPTION_ID: $SUBSCRIPTION_ID"

echo -e "\nConfiguration OIDC termin√©e avec succ√®s pour les deux applications."
```

## D√©ploiement de l'Infrastructure As Code (IaC)

Le code infrastructure est disponible sur son repository d√©di√© : [openmrs-core-infrastructure](https://github.com/AudioProthese/openmrs-core-infrastructure).

Ci-dessous l'organisation des fichiers de configuration Terraform : 

```plaintext
terraform/
‚îî‚îÄ‚îÄ prod/                    # Environnement Prod
    ‚îú‚îÄ‚îÄ aks.tf               # Cluster AKS
    ‚îú‚îÄ‚îÄ acr.tf               # Azure Container Registry
    ‚îú‚îÄ‚îÄ data.tf              # Data sources
    ‚îú‚îÄ‚îÄ dns.tf               # DNS Azure
    ‚îú‚îÄ‚îÄ helm.tf              # Helm charts
    ‚îú‚îÄ‚îÄ identity.tf          # Identity: Federation & r√¥le OIDC
    ‚îú‚îÄ‚îÄ manifests.tf         # Manifests Kubernetes
    ‚îú‚îÄ‚îÄ outputs.tf           # Export des variables utiles
    ‚îú‚îÄ‚îÄ providers.tf         # Configuration des providers (Azure, Kubernetes)
    ‚îú‚îÄ‚îÄ variables.tf         # D√©claration des variables d'entr√©e
    ‚îî‚îÄ‚îÄ vault.tf             # Azure Key Vault
```

### Configuration de la pipeline CI/CD

Il est n√©cessaire de configurer la pipeline CI/CD pour automatiser le d√©ploiement de l'infrastructure et des applications. Les diff√©rentes pipelines sont d√©finies dans le dossier `.github/workflows` du d√©p√¥t GitHub. Voici un exemple de configuration pour le d√©ploiement de l'infrastructure en DEV :

```yaml
name: Apply Terraform plan (DEV)

on:
  push:
    branches:
      - main
    paths:
      - 'terraform/dev/**'

permissions:
  contents: read
  pull-requests: write
  id-token: write

jobs:
  apply:
    uses: ./.github/workflows/terraform-apply.yml
    with:
      environment: dev
    secrets: inherit
```

### Briques d'infrastructure manag√©es par Terraform

La CI/CD d√©ploiera les briques d'infrastructure suivantes :

| Composant                | Description                                                      |
| ------------------------ | ---------------------------------------------------------------- |
| **AKS**                  | Cluster Kubernetes manag√© avec Workload Identity et OIDC         |
| **ACR**                  | Azure Container Registry connect√© √† AKS                          |
| **Azure Key Vault**      | Pour la gestion des secrets (RBAC activ√©)                        |
| **Azure DNS**            | Zone publique utilis√©e pour le routage et les certificats        |
| **OIDC Federation**      | F√©d√®re un SA Kubernetes avec Azure AD                            |
| **Helm Charts**          | D√©ploiement de ArgoCD.                                           |
| **Manifests Kubernetes** | ClusterIssuer, Ingress, ESO CRD. inject√©s via `kubectl_manifest` |

Le cluster Kubernetes (AKS) est configur√© de cette mani√®re : 

- **Managed Identity** activ√©e (SystemAssigned)
- **OIDC + Workload Identity** (`oidc_issuer_enabled = true`)
- **Web App Routing** int√©gr√© avec liaison √† la zone DNS
- Un **pools de n≈ìuds default** (2 n≈ìuds, D2_v2)

```hcl
resource "azurerm_kubernetes_cluster" "aks" {
  ...
  workload_identity_enabled = true
  oidc_issuer_enabled       = true
  web_app_routing {
    dns_zone_ids = [azurerm_dns_zone.audioprothese_ovh.id]
  }
}
```

Le registre ACR est priv√© et configur√© avec :

- **R√¥le `AcrPull` assign√© au kubelet identity** du cluster

```hcl
resource "azurerm_role_assignment" "acr_pull" {
  principal_id = azurerm_kubernetes_cluster.aks.kubelet_identity[0].object_id
  role_definition_name = "AcrPull"
}
```

Le Key Vault est cr√©√© avec :

- **RBAC activ√©**
- **Soft delete** actif (7 jours)
- R√¥le `Key Vault Secrets User` assign√© au kubelet AKS

```hcl
enable_rbac_authorization = true
purge_protection_enabled  = false
```

La zone DNS publique `audioprothese.ovh` est g√©r√©e dans Azure et permet :

- Le routage via Web App Routing (AKS)
- Les d√©fis DNS-01 (cert-manager)

Deux r√¥les `DNS Zone Contributor` sont assign√©s :

- Kubelet Identity (ExternalDNS)
- WebAppRouting Identity (ingress cert-manager)

Un SA Kubernetes (`workload-identity-sa`) est f√©d√©r√© avec Azure AD :

```hcl
resource "azurerm_federated_identity_credential" "ESOFederatedIdentity" {
  issuer  = azurerm_kubernetes_cluster.aks.oidc_issuer_url
  subject = "system:serviceaccount:default:workload-identity-sa"
}
```

Cela permet √† des pods d‚Äôassumer un r√¥le Azure via OIDC sans secrets.

Les composants suivants sont d√©ploy√©s avec `helm_release` et `kubectl_manifest` :

| Composant    | Type     | Description                  |
| ------------ | -------- | ---------------------------- |
| ArgoCD       | Helm     | Helm chart ArgoCD            |
| OpenMRS      | Manifest | Ingress OpenMRS              |
| ESO          | Manifest | CRD External Secret Operator |
| cert-manager | Manifest | CRD cert-manager             |

# FAQ interne

## Quel est le p√©rim√®tre de la mission DevOps ?

Le p√©rim√®tre couvre :

- La mise en place d'une infrastructure Cloud Azure manag√©e via Terraform
- Le d√©ploiement et l‚Äôautomatisation d‚Äôun cluster AKS avec CI/CD
- L'int√©gration d'une solution de supervision compl√®te (Prometheus, Grafana, Alertmanager)
- La s√©curit√© des secrets via Azure Key Vault + External Secrets Operator
- L'int√©gration de l‚Äôapplication OpenMRS en environnement Dev et Prod

---

## Quels environnements sont g√©r√©s ?

Deux environnements sont d√©finis :

- **dev** : pour les tests, d√©veloppements et it√©rations fr√©quentes
- **prod** : pour les mises en production valid√©es et stables

Chaque environnement poss√®de :

- Son propre backend Terraform (Storage Account isol√©)
- Son propre cluster AKS
- Des secrets, r√¥les et configurations sp√©cifiques

---

## O√π sont stock√©s les secrets ?

Les secrets sont stock√©s de mani√®re s√©curis√©e dans **Azure Key Vault**.  
Ils sont synchronis√©s dans Kubernetes √† l'aide d‚Äô**External Secrets Operator**, ce qui √©vite tout stockage dans Git ou dans les manifests.

Actuellement, cela est utilis√© dans le namespace `authgate`, mais l'architecture permet de l‚Äô√©tendre √† tous les namespaces.

---

## Comment se fait l‚Äôauthentification depuis la CI/CD vers Azure ?

Nous utilisons **OIDC (Workload Identity Federation)** avec GitHub Actions.  
Cela √©vite de stocker des secrets dans les workflows et repose sur des identit√©s manag√©es s√©curis√©es.

---

## O√π sont stock√©s les √©tats Terraform ?

Les fichiers `terraform.tfstate` sont stock√©s dans des **Azure Storage Accounts**, un par environnement :

- Container `tfstate-dev` pour dev
- Container `tfstate-prod` pour prod

Ces containers doivent √™tre initialis√©s manuellement une fois au bootstrap.

---

## Comment consulter les dashboards et alertes ?

Les dashboards Grafana sont disponibles sur l'URL publique du cluster, expos√©s via Ingress avec certificat TLS.  
Les alertes sont g√©r√©es par Alertmanager, et envoy√©es vers Telegram.

---

## Comment contribuer ou modifier l'infrastructure ?

Les modifications doivent √™tre faites via :

- Des branches Git suivies de Pull Requests
- L‚Äôex√©cution des pipelines GitHub Actions (lint, plan, apply)
- Respect des bonnes pratiques de versioning et de validation manuelle avant `terraform apply`

---

## Quels sont les outils utilis√©s dans le projet ?

- **Terraform** : Provisionnement de l‚Äôinfrastructure Azure
- **Helm** : D√©ploiement des composants Kubernetes
- **Trivy** : Scan de vuln√©rabilit√©s des images Docker
- **Prometheus / Grafana / Alertmanager** : Supervision
- **Azure Key Vault + ESO** : Gestion des secrets
- **GitHub Actions** : CI/CD avec OIDC Azure

---

## √Ä qui s‚Äôadresser en cas de question technique ?

Tu peux contacter l'ing√©nieur DevOps r√©f√©rent du projet via Teams ou Slack, ou consulter la [page Contacts](../annexes/contacts.md) pour les informations √† jour.

---
